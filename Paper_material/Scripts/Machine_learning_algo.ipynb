{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95864d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb00c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"C:/Users/Fousseini KOUYATE/Desktop/Paper_material/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba887782",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('DATA.csv', sep=\";\")\n",
    "data['T'] = pd.to_datetime(data['T'])\n",
    "Tim = data['T']\n",
    "data['WL_Pank'] = data['WL_Pank'] * 0.01\n",
    "data['WL_Sof'] = data['WL_Sof'] * 0.01\n",
    "data['WL_Bou'] = data['WL_Bou'] * 0.01\n",
    "data['WL_Dou'] = data['WL_Dou'] * 0.01\n",
    "data['WL_Mop'] = data['WL_Mop'] * 0.01\n",
    "\n",
    "data['P'] = data['P'] * 0.001\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b85c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independantes (inputs) et dependante (target) - variables\n",
    "X = data[['Tot_evap', 'WL_Bou', 'WL_Sof', 'WL_Pank', 'P', 'WL_Dou', 'WTD']]  # Inputs\n",
    "y = data['WL_Mop']  # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "svm_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Find the starting dates of X_train and X_test by using the indices to reference the original dataframe\n",
    "starting_date_X_train = data.loc[X_train.index, 'T'].min()\n",
    "starting_date_X_test = data.loc[X_test.index, 'T'].min()\n",
    "ending_date_X_train = data.loc[X_train.index, 'T'].max()\n",
    "ending_date_X_test = data.loc[X_test.index, 'T'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd02da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, learning_rate=0.1),\n",
    "    'SVM': SVR(kernel='rbf', C=1.0, epsilon=0.1),\n",
    "    'XGBoosting': XGBRegressor(n_estimators=100)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Training\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    # Prediction\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    # Cross-validation\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train, cv=4, scoring='neg_mean_squared_error')\n",
    "    mean_score = np.mean(np.sqrt(-scores))\n",
    "    \n",
    "    results[name] = {'RMSE': rmse, 'Cross Validation Score': mean_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa46d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = min(results, key=lambda x: results[x]['Cross Validation Score'])\n",
    "best_model_performance = results[best_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5822247",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model_names = list(results.keys())\n",
    "rmse_scores = [results[name]['RMSE'] for name in model_names]\n",
    "cv_scores = [results[name]['Cross Validation Score'] for name in model_names]\n",
    "width  = 0.3\n",
    "x = np.arange(len(model_names)) \n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.figure(figsize=(10, 6))\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x, rmse_scores, width, label='RMSE')\n",
    "rects2 = ax.bar(x + width/2, cv_scores, width, label='CV Score')\n",
    "\n",
    "ax.set_ylabel('RMSE (m)')\n",
    "ax.set_title('(d)', loc='left')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_names)\n",
    "\n",
    "plt.xticks(rotation=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f622c7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "def calculate_nse(y_true, y_pred):\n",
    "    return 1 - (np.sum((y_true - y_pred) ** 2) / np.sum((y_true - np.mean(y_true)) ** 2))\n",
    "\n",
    "def calculate_pbias(y_true, y_pred):\n",
    "    return (np.sum(y_true - y_pred) / np.sum(y_true)) * 100\n",
    "\n",
    "def calculate_pabe(y_true, y_pred):\n",
    "    return (np.sum(np.abs(y_true - y_pred)) / np.sum(y_true)) * 100\n",
    "\n",
    "nse = calculate_nse(y_test, y_pred)\n",
    "pbias = calculate_pbias(y_test, y_pred)\n",
    "pabe = calculate_pabe(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "y_pred\n",
    "X_test_scaled\n",
    "predictions = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    predictions[model_name] = model.predict(X_test_scaled)\n",
    "\n",
    "for model_name, model_predictions in predictions.items():\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, model_predictions))\n",
    "    nse = calculate_nse(y_test, model_predictions)\n",
    "    pabe = calculate_pabe(y_test, model_predictions)\n",
    "    pbias = calculate_pbias(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, model_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b064bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "# Defining the functions as provided\n",
    "def calculate_nse(y_true, y_pred):\n",
    "    return 1 - (np.sum((y_true - y_pred) ** 2) / np.sum((y_true - np.mean(y_true)) ** 2))\n",
    "\n",
    "def calculate_pbias(y_true, y_pred):\n",
    "    return (np.sum(y_true - y_pred) / np.sum(y_true)) * 100\n",
    "\n",
    "def calculate_pabe(y_true, y_pred):\n",
    "    return (np.sum(np.abs(y_true - y_pred)) / np.sum(y_true)) * 100\n",
    "\n",
    "# Preparing to calculate the metrics for each model\n",
    "evaluation_results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Predicting with the current model\n",
    "    model_predictions = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculating metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, model_predictions))\n",
    "    nse = calculate_nse(y_test, model_predictions)\n",
    "    pabe = calculate_pabe(y_test, model_predictions)\n",
    "    pbias = calculate_pbias(y_test, model_predictions)\n",
    "    r2 = r2_score(y_test, model_predictions)\n",
    "    mae = mean_absolute_error(y_test, model_predictions)\n",
    "    \n",
    "    # Storing results\n",
    "    evaluation_results[model_name] = {\n",
    "        'RMSE': rmse, \n",
    "        'R^2': r2, \n",
    "        'NSE': nse, \n",
    "        'PABE': pabe, \n",
    "        'PBIAS': pbias,\n",
    "        'MAE': mae\n",
    "    }\n",
    "\n",
    "evaluation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc1fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "# Assuming you have 4 models, for a 2x2 grid\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 6), sharey=True)\n",
    "axs = axs.flatten()  # Flatten the 2x2 array to make iterating over it easier\n",
    "\n",
    "# Définition des nouveaux titres pour chaque graphique\n",
    "new_titles = ['(a)', '(b)', '(c)', '(d)']\n",
    "\n",
    "for i, (model_name, model) in enumerate(models.items()):\n",
    "    model_predictions = model.predict(X_test_scaled)\n",
    "    axs[i].scatter(y_test, model_predictions, alpha=0.3, color='black')\n",
    "    axs[i].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    # Positioning the title in the lower right inside the figure box\n",
    "    axs[i].text(0.95, 0.05, new_titles[i], horizontalalignment='right', verticalalignment='bottom', transform=axs[i].transAxes, fontsize=14, color='black')\n",
    "    r2 = r2_score(y_test, model_predictions)\n",
    "    axs[i].text(0.05, 0.95, f'R²={r2:.3f}', transform=axs[i].transAxes, verticalalignment='top', color='black', fontsize=12)\n",
    "\n",
    "# Set the ylabel for subplots (a) and (c)\n",
    "axs[0].set_ylabel('Predicted water level (m)', fontsize=14)\n",
    "axs[2].set_ylabel('Predicted water level (m)', fontsize=14)\n",
    "\n",
    "# Set the xlabel for subplots (c) and (d)\n",
    "axs[2].set_xlabel('Observed water level (m)', fontsize=14)\n",
    "axs[3].set_xlabel('Observed water level (m)', fontsize=14)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e8456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBRegressor_model = XGBRegressor(n_estimators=100)\n",
    "XGBRegressor_model.fit(X_train_scaled, y_train)\n",
    "y_pred = XGBRegressor_model.predict(X_test_scaled)\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'RMSE: {rmse}')\n",
    "feature_importances = XGBRegressor_model.feature_importances_\n",
    "plt.figure(figsize=(17, 6))\n",
    "plt.barh(range(X.shape[1]), feature_importances, align='center')\n",
    "plt.yticks(np.arange(X.shape[1]), X.columns, fontsize=16)\n",
    "plt.xlabel('Feature Importance', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7075e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Supposons que X_train_scaled, y_train, X, et results sont déjà définis\n",
    "# Instantiate the models\n",
    "RandomForest_model = RandomForestRegressor(n_estimators=100)\n",
    "GradientBoosting_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1)\n",
    "\n",
    "# Fit the models on the training data\n",
    "RandomForest_model.fit(X_train_scaled, y_train)\n",
    "GradientBoosting_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "RandomForest_feature_importances = RandomForest_model.feature_importances_\n",
    "GradientBoosting_feature_importances = GradientBoosting_model.feature_importances_\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "# Create a subplot grid of 2x2\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 6))\n",
    "\n",
    "# Random Forest Feature Importances\n",
    "axs[0, 0].barh(np.arange(X.shape[1]), RandomForest_feature_importances, align='center')\n",
    "axs[0, 0].set_yticks(np.arange(X.shape[1]))\n",
    "axs[0, 0].set_yticklabels(X.columns, fontsize=14)\n",
    "axs[0, 0].set_title('(e)', loc='left')\n",
    "\n",
    "# Gradient Boosting Feature Importances\n",
    "axs[0, 1].barh(np.arange(X.shape[1]), GradientBoosting_feature_importances, align='center')\n",
    "axs[0, 1].set_yticks(np.arange(X.shape[1]))\n",
    "axs[0, 1].set_yticklabels(X.columns, fontsize=14)\n",
    "axs[0, 1].set_title('(f)', loc='left')\n",
    "\n",
    "# Placeholder for XGBoost (replace 'feature_importances' with actual values)\n",
    "axs[1, 0].barh(np.arange(X.shape[1]), feature_importances, align='center')\n",
    "axs[1, 0].set_yticks(np.arange(X.shape[1]))\n",
    "axs[1, 0].set_xlabel('Feature Importance', fontsize=14)\n",
    "axs[1, 0].set_yticklabels(X.columns, fontsize=14)\n",
    "axs[1, 0].set_title('(g)', loc='left')\n",
    "\n",
    "# Placeholder for RMSE and CV Scores\n",
    "model_names = list(results.keys())\n",
    "rmse_scores = [results[name]['RMSE'] for name in model_names]\n",
    "cv_scores = [results[name]['Cross Validation Score'] for name in model_names]\n",
    "width = 0.3\n",
    "x = np.arange(len(model_names))\n",
    "rects1 = axs[1, 1].bar(x - width/2, rmse_scores, width, label='RMSE')\n",
    "rects2 = axs[1, 1].bar(x + width/2, cv_scores, width, label='CV Score')\n",
    "axs[1, 1].set_ylabel('RMSE (m)')\n",
    "axs[1, 1].set_title('(h)', loc='left')\n",
    "axs[1, 1].set_xticks(x)\n",
    "axs[1, 1].set_xticklabels(model_names, rotation=20, ha='right')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516ed074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Assuming X_train_scaled, y_train, X, and results are already defined\n",
    "# Instantiate the models\n",
    "RandomForest_model = RandomForestRegressor(n_estimators=100)\n",
    "GradientBoosting_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1)\n",
    "\n",
    "# Fit the models on the training data\n",
    "RandomForest_model.fit(X_train_scaled, y_train)\n",
    "GradientBoosting_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "RandomForest_feature_importances = RandomForest_model.feature_importances_\n",
    "GradientBoosting_feature_importances = GradientBoosting_model.feature_importances_\n",
    "\n",
    "# Adjust font size for all plots\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# Subplot for Random Forest Feature Importances\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.barh(np.arange(X.shape[1]), RandomForest_feature_importances, align='center')\n",
    "plt.yticks(np.arange(X.shape[1]), X.columns, fontsize=14)\n",
    "plt.xlabel('', fontsize=14)\n",
    "plt.text(0.95, 0.95, '(a)', horizontalalignment='right', verticalalignment='top', transform=plt.gca().transAxes, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"RandomForest_Feature_Importance.png\", format='png', dpi=300)\n",
    "\n",
    "# Subplot for Gradient Boosting Feature Importances\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.barh(np.arange(X.shape[1]), GradientBoosting_feature_importances, align='center')\n",
    "plt.yticks(np.arange(X.shape[1]), X.columns, fontsize=14)\n",
    "plt.xlabel('', fontsize=14)\n",
    "plt.text(0.95, 0.95, '(b)', horizontalalignment='right', verticalalignment='top', transform=plt.gca().transAxes, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"GradientBoosting_Feature_Importance.png\", format='png', dpi=300)\n",
    "\n",
    "# Placeholder for XGBoost Feature Importances (Assuming 'feature_importances' is defined)\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.barh(np.arange(X.shape[1]), feature_importances, align='center')  # Ensure 'feature_importances' is defined\n",
    "plt.yticks(np.arange(X.shape[1]), X.columns, fontsize=14)\n",
    "plt.xlabel('Feature Importance', fontsize=14)\n",
    "plt.text(0.95, 0.95, '(c)', horizontalalignment='right', verticalalignment='top', transform=plt.gca().transAxes, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"XGBoost_Feature_Importance.png\", format='png', dpi=300)\n",
    "\n",
    "# Placeholder for RMSE and CV Scores (Assuming 'results' is defined)\n",
    "plt.figure(figsize=(5, 3))\n",
    "model_names = list(results.keys())\n",
    "rmse_scores = [results[name]['RMSE'] for name in model_names]\n",
    "cv_scores = [results[name]['Cross Validation Score'] for name in model_names]\n",
    "width = 0.3\n",
    "x = np.arange(len(model_names))\n",
    "plt.bar(x - width/2, rmse_scores, width, label='RMSE')\n",
    "plt.bar(x + width/2, cv_scores, width, label='CV Score')\n",
    "plt.ylabel('RMSE (m)', fontsize=12)\n",
    "plt.text(0.05, 0.95, '(f)', horizontalalignment='left', verticalalignment='top', transform=plt.gca().transAxes, fontsize=14)\n",
    "plt.xticks(x, model_names, rotation=10, ha='center', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"RMSE_CV_Scores.png\", format='png', dpi=300)\n",
    "\n",
    "# Show the last figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3646f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test_time Series with the correct index\n",
    "test_time = Tim.loc[X_test.index]\n",
    "\n",
    "# Ensure that the index of test_time aligns with y_test\n",
    "test_time = test_time.reset_index(drop=True)\n",
    "\n",
    "# Convert XGBRegressor_predictions to a NumPy array if it isn't already one\n",
    "XGBRegressor_predictions = np.array(predictions['XGBoosting'])\n",
    "# Convert XGBRegressor_predictions to a NumPy array if it isn't already one\n",
    "SVR_predictions = np.array(predictions['SVM'])\n",
    "# Convert XGBRegressor_predictions to a NumPy array if it isn't already one\n",
    "GB_predictions = np.array(predictions['Gradient Boosting'])\n",
    "# Convert XGBRegressor_predictions to a NumPy array if it isn't already one\n",
    "RF_predictions = np.array(predictions['Random Forest'])\n",
    "\n",
    "# Ensure that y_test is a Pandas Series with the correct index\n",
    "y_test = pd.Series(y_test).reset_index(drop=True)\n",
    "\n",
    "# Create the comparison DataFrame\n",
    "df_comparison = pd.DataFrame({\n",
    "    'Date': test_time,  # Adding the date column\n",
    "    'Observed': y_test,\n",
    "    'Predicted SVM': SVR_predictions,\n",
    "    'Predicted Random Forest': RF_predictions\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "df_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c2d399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the comparison DataFrame\n",
    "df1_comparison = pd.DataFrame({\n",
    "    'Date': test_time,  # Adding the date column\n",
    "    'Observed': y_test,\n",
    "    'Predicted SVM': SVR_predictions,\n",
    "    'Predicted Random Forest': RF_predictions,\n",
    "    'Predicted XGBoost': XGBRegressor_predictions,\n",
    "    'Predicted Gradient Boosting': GB_predictions\n",
    "})\n",
    "df1_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b75ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming the DataFrame df1_comparison is defined as follows:\n",
    "date_range = pd.date_range(start='2013-05-27', end='2020-12-31', freq='D')\n",
    "df1_comparison = pd.DataFrame({\n",
    "    'Date': date_range,\n",
    "    'Observed': y_test,\n",
    "    'Predicted SVM': SVR_predictions,\n",
    "    'Predicted Random Forest': RF_predictions,\n",
    "    'Predicted XGBoost': XGBRegressor_predictions,\n",
    "    'Predicted Gradient Boosting': GB_predictions\n",
    "})\n",
    "\n",
    "# Define the models you want to plot\n",
    "models = ['SVM', 'Random Forest', 'XGBoost', 'Gradient Boosting']  # Match these names with your DataFrame columns\n",
    "\n",
    "# Colors for each model\n",
    "colors = ['blue', 'green', 'red', 'purple']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=1, figsize=(10, 14), sharex=True)\n",
    "\n",
    "for idx, model in enumerate(models):\n",
    "    axes[idx].plot(df1_comparison['Date'], df1_comparison['Observed'], label='Observed', color='black', linestyle='-', linewidth=1.5)\n",
    "    axes[idx].plot(df1_comparison['Date'], df1_comparison[f'Predicted {model}'], label=f'{model}', color=colors[idx], linestyle='-', linewidth=1.5)\n",
    "    axes[idx].set_ylabel('Water Level (m)')\n",
    "    axes[idx].set_ylim(0, 7.5) \n",
    "    axes[idx].legend(loc='upper left', fontsize=14, framealpha=0, ncol=2)\n",
    "    # Annotate in the bottom right with the figure label (a, b, c, d)\n",
    "    axes[idx].annotate(f'({chr(97 + idx)})', xy=(0.95, 0.05), xycoords='axes fraction', fontsize=18, ha='right', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Save the combined plot\n",
    "fig.savefig(\"All_Models_Comparison.png\", format='png', dpi=300)\n",
    "plt.close(fig)  # Close the figure after saving to free up memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a011ca9b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df1_comparison' DataFrame is already loaded and contains a 'Date' and relevant data columns\n",
    "# Convert 'Date' to 'Year' and group by 'Year' to find maximum values (peak flows)\n",
    "df1_comparison['Year'] = df1_comparison['Date'].dt.year\n",
    "annual_peaks = df1_comparison.groupby('Year').max()\n",
    "\n",
    "# Filtering out the 'Date' column since it's not needed for plotting the water levels\n",
    "annual_peaks_numeric = annual_peaks.select_dtypes(include=[np.number])\n",
    "\n",
    "# Setting up the bar plot with better spacing and color differentiation\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Width of the bars adjusted to reduce overlap\n",
    "width = 0.12\n",
    "\n",
    "# Improved color scheme for better differentiation\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "\n",
    "# Set position of bars on X axis\n",
    "positions = np.arange(len(annual_peaks_numeric))\n",
    "\n",
    "# Enumerate through the columns to set up individual bar plots for each prediction model\n",
    "for i, (column, color) in enumerate(zip(annual_peaks_numeric.columns, colors)):\n",
    "    plt.bar(positions + i * width, annual_peaks_numeric[column], color=color, width=width, edgecolor='grey', label=column)\n",
    "\n",
    "\n",
    "plt.ylabel('Peak Water Level (m)', fontsize=14)\n",
    "\n",
    "# Add figure number at the top right side in the plot box\n",
    "plt.text(0.99, 0.99, '(a)', transform=plt.gca().transAxes, fontsize=18, ha='right', verticalalignment='top')\n",
    "\n",
    "# Adjust x-ticks to be in the center of the grouped bars\n",
    "plt.xticks(positions + width * (len(annual_peaks_numeric.columns) - 1) / 2, annual_peaks_numeric.index, fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "# Set y-axis limits dynamically to ensure all data is well framed\n",
    "plt.ylim(5, annual_peaks_numeric.max().max() * 1.1)  # Extending the y-axis limit based on the maximum value\n",
    "\n",
    "# Place a legend at the top left of the plot box inside\n",
    "plt.legend(loc='upper left', fontsize=14,  framealpha=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Peak_Water_Levels_by_Model.png\", format='png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b404a6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "annual_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c859964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df1_comparison' DataFrame is already loaded and contains a 'Date' and relevant data columns\n",
    "# For demonstration, I'll use the previously created DataFrame structure\n",
    "\n",
    "# Convert 'Date' to 'Year'\n",
    "df1_comparison['Year'] = df1_comparison['Date'].dt.year\n",
    "\n",
    "# Group by 'Year' and find the minimum value for each year to get annual lows\n",
    "annual_low = df1_comparison.groupby('Year').min()\n",
    "\n",
    "# Setting up the bar plot\n",
    "plt.figure(figsize=(7, 5))  # Adjusted for better visualization\n",
    "\n",
    "# Width of the bars\n",
    "width = 0.15\n",
    "\n",
    "# Define colors for each predicted model and observed data\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "\n",
    "# Set position of bars on X axis\n",
    "positions = np.arange(len(annual_low))\n",
    "\n",
    "# Enumerate through the columns to set up individual bar plots for each prediction model\n",
    "for i, (column, color) in enumerate(zip(annual_low.columns, colors)):\n",
    "    if 'Predicted' in column or 'Observed' in column:\n",
    "        # Plot bars with offset positions so they don't overlap\n",
    "        plt.bar(positions + i * width, annual_low[column], color=color, width=width, edgecolor='grey', label=column)\n",
    "\n",
    "plt.ylabel('Low Water Level (m)', fontsize=14)\n",
    "\n",
    "# Add figure number at the top left side in the plot box\n",
    "plt.text(0.01, 0.99, '(b)', transform=plt.gca().transAxes, fontsize=14, verticalalignment='top')\n",
    "\n",
    "# Adjust x-ticks to be in the center of the grouped bars\n",
    "plt.xticks(positions + width * (len(annual_low.columns) - 2) / 2, annual_low.index, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Set y-axis limits to ensure all data is nicely framed\n",
    "plt.ylim(0.4, 1.2)\n",
    "plt.legend(loc='upper center', fontsize=8, framealpha=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Annual_Low_Water_Levels.png\", format='png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8a28d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df1_comparison' DataFrame is already loaded and contains a 'Date' and relevant data columns\n",
    "# Convert 'Date' to 'Year' and group by 'Year' to find the minimum values (annual lows)\n",
    "df1_comparison['Year'] = df1_comparison['Date'].dt.year\n",
    "annual_lows = df1_comparison.groupby('Year').min()\n",
    "\n",
    "# Filtering out the 'Date' column since it's not needed for plotting the water levels\n",
    "annual_lows_numeric = annual_lows.select_dtypes(include=[np.number])\n",
    "\n",
    "# Setting up the bar plot with better spacing and color differentiation\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Width of the bars adjusted to reduce overlap\n",
    "width = 0.12\n",
    "\n",
    "# Improved color scheme for better differentiation\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "\n",
    "# Set position of bars on X axis\n",
    "positions = np.arange(len(annual_lows_numeric))\n",
    "\n",
    "# Enumerate through the columns to set up individual bar plots for each prediction model\n",
    "for i, (column, color) in enumerate(zip(annual_lows_numeric.columns, colors)):\n",
    "    if 'Predicted' in column or 'Observed' in column:\n",
    "        plt.bar(positions + i * width, annual_lows_numeric[column], color=color, width=width, edgecolor='grey', label=column)\n",
    "\n",
    "plt.ylabel('Low Water Level (m)', fontsize=16)\n",
    "\n",
    "\n",
    "# Add figure number at the top right side in the plot box\n",
    "plt.text(0.99, 0.99, '(b)', transform=plt.gca().transAxes, fontsize=18, ha='right', verticalalignment='top')\n",
    "\n",
    "# Adjust x-ticks to be in the center of the grouped bars\n",
    "plt.xticks(positions + width * (len(annual_lows_numeric.columns) - 1) / 2, annual_lows_numeric.index, fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "# Set y-axis limits dynamically to ensure all data is well framed\n",
    "plt.ylim(0, 1.7)  # Setting the upper limit to 2 as requested\n",
    "\n",
    "# Place a legend at the top left of the plot box inside\n",
    "plt.legend(loc='upper left', fontsize=14, framealpha=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Annual_Low_Water_Levels_by_Model.png\", format='png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf05ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_comparison is already prepared and sorted chronologically.\n",
    "years = range(2014, 2021)  # Example range of years\n",
    "\n",
    "# Starting and ending indices for the slice\n",
    "start_idx = 1130\n",
    "end_idx = 1030 + 340\n",
    "\n",
    "# Slicing the DataFrame to obtain only the first segment\n",
    "data_filtered = df_comparison.iloc[start_idx:end_idx]\n",
    "\n",
    "# Generate date labels for the x-axis based on the sliced segment\n",
    "date_labels = df_comparison['Date'].iloc[start_idx:end_idx].dt.strftime('%Y-%m-%d').values\n",
    "\n",
    "# Display frequency: e.g., every 10 days\n",
    "display_frequency = (70)\n",
    "\n",
    "# Filter date labels to display according to the chosen frequency\n",
    "filtered_date_labels = date_labels[::display_frequency]\n",
    "# Calculate the corresponding indices for these labels (for setting ticks)\n",
    "display_indices = range(0, len(date_labels), display_frequency)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "# Create a figure and a single axis for only the first segment\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "# Plotting each series in the sliced segment\n",
    "ax.plot(range(len(date_labels)), data_filtered['Observed'], color='k', linestyle='-', linewidth=1)\n",
    "ax.plot(range(len(date_labels)), data_filtered['Predicted XGBoosting'], linestyle='-', linewidth=1)\n",
    "ax.plot(range(len(date_labels)), data_filtered['Predicted SVM'], linestyle='-', linewidth=1)\n",
    "ax.plot(range(len(date_labels)), data_filtered['Predicted Gradient Boosting'], linestyle='-', linewidth=1)\n",
    "ax.plot(range(len(date_labels)), data_filtered['Predicted Random Forest'], linestyle='-', linewidth=1)\n",
    "\n",
    "# Adjusting x-axis labels for readability\n",
    "plt.xticks(ticks=display_indices, labels=filtered_date_labels, rotation=0, ha=\"center\", fontsize=16)\n",
    "\n",
    "# Setting Y-axis label\n",
    "ax.set_ylabel('Water Level (m)', fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Fig_zoom.png\", format='png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ebdea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, ensure that the 'Year' column and 'annual_peaks' DataFrame are correctly set up as before.\n",
    "df_comparison['Year'] = df_comparison['Date'].dt.year\n",
    "annual_peaks = df_comparison.groupby('Year').max()\n",
    "\n",
    "# Then, plotting each model's and the observed data's annual peak flow values.\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for column in annual_peaks.columns:\n",
    "    if 'Predicted' in column or 'Observed' in column:\n",
    "        plt.plot(annual_peaks.index, annual_peaks[column], marker='o', label=column)\n",
    "\n",
    "plt.xlabel('Year', fontsize=18)\n",
    "plt.ylabel('Low Water Level (m)', fontsize=17)\n",
    "plt.title('')\n",
    "plt.xticks(annual_peaks.index, rotation=0, fontsize=17)  # Ensure all years are shown and rotate for readability\n",
    "plt.yticks(fontsize=17)\n",
    "plt.legend(fontsize=17)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08828fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'df_comparison' and 'annual_peaks' are set up correctly\n",
    "df_comparison['Year'] = df_comparison['Date'].dt.year\n",
    "annual_peaks = df_comparison.groupby('Year').max()\n",
    "\n",
    "# Setting up the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plotting each model's and the observed data's annual peak flow values\n",
    "for column in annual_peaks.columns:\n",
    "    if 'Predicted' in column or 'Observed' in column:\n",
    "        plt.plot(annual_peaks.index, annual_peaks[column], marker='o', label=column)\n",
    "\n",
    "# Customizing labels and title\n",
    "plt.xlabel('Year', fontsize=18)\n",
    "plt.ylabel('Peak Water Level (m)', fontsize=17)  # Changed from 'Low' to 'Peak' for accuracy\n",
    "plt.title('Annual Peak Water Levels by Model', fontsize=18)  # Added a title for clarity\n",
    "\n",
    "# Setting x and y axis properties\n",
    "plt.xticks(annual_peaks.index, rotation=0, fontsize=17)  # Ensure all years are shown\n",
    "plt.yticks(fontsize=17)\n",
    "\n",
    "# Setting y-axis limits from 5 to 7\n",
    "plt.ylim(5, 7)\n",
    "\n",
    "# Adding a legend\n",
    "plt.legend(fontsize=12)  # Adjusted font size for better readability within the figure\n",
    "\n",
    "# Adjusting layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fbdd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, ensure that the 'Year' column and 'annual_peaks' DataFrame are correctly set up as before.\n",
    "df_comparison['Year'] = df_comparison['Date'].dt.year\n",
    "annual_low = df_comparison.groupby('Year').min()\n",
    "\n",
    "# Then, plotting each model's and the observed data's annual peak flow values.\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for column in annual_peaks.columns:\n",
    "    if 'Predicted' in column or 'Observed' in column:\n",
    "        plt.plot(annual_low.index, annual_low[column], marker='o', label=column)\n",
    "\n",
    "plt.xlabel('Year', fontsize=18)\n",
    "plt.ylabel('Peak Water Level (m)', fontsize=18)\n",
    "plt.title('Annual Peak Water Levels by Model')\n",
    "plt.xticks(annual_peaks.index, rotation=0, fontsize=18)  # Ensure all years are shown and rotate for readability\n",
    "plt.legend(fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29f1ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
