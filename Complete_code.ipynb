{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2c8d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d71ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the dataset\n",
    "data = pd.read_csv('data/DATA.csv', sep=\";\")\n",
    "data['T'] = pd.to_datetime(data['T'], dayfirst=True)\n",
    "data['WL_Pank'] = data['WL_Pank'] * 0.01\n",
    "data['WL_Sof'] = data['WL_Sof'] * 0.01\n",
    "data['WL_Bou'] = data['WL_Bou'] * 0.01\n",
    "data['WL_Dou'] = data['WL_Dou'] * 0.01\n",
    "data['WL_Mop'] = data['WL_Mop'] * 0.01\n",
    "data['P'] = data['P'] * 0.001\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efa02d8",
   "metadata": {},
   "source": [
    "# CV FOLD 1 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92c94e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your dataset and prepare it as usual\n",
    "# Assuming data is already loaded and preprocessed as needed\n",
    "\n",
    "# Define X and y\n",
    "X_fold1 = data[['Tot_evap', 'WL_Sof', 'WL_Bou', 'WL_Pank', 'P', 'WL_Dou', 'WTD']]  # Inputs\n",
    "y_fold1 = data['WL_Mop']  # Target\n",
    "\n",
    "# Split the data: first 60% training, middle 20% testing, last 20% validation\n",
    "train_size = int(0.6 * len(X_fold1))\n",
    "test_size = int(0.2 * len(X_fold1))\n",
    "\n",
    "# The first 60% for training\n",
    "X_train_fold1 = X_fold1.iloc[:train_size]\n",
    "y_train_fold1 = y_fold1.iloc[:train_size]\n",
    "\n",
    "# The next 20% for testing\n",
    "X_test_fold1 = X_fold1.iloc[train_size:train_size + test_size]\n",
    "y_test_fold1 = y_fold1.iloc[train_size:train_size + test_size]\n",
    "\n",
    "# The last 20% for validation\n",
    "X_val_fold1 = X_fold1.iloc[train_size + test_size:]\n",
    "y_val_fold1 = y_fold1.iloc[train_size + test_size:]\n",
    "\n",
    "# Scale the data\n",
    "scaler_fold1 = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform all datasets\n",
    "X_train_scaled_fold1 = scaler_fold1.fit_transform(X_train_fold1)\n",
    "X_val_scaled_fold1 = scaler_fold1.transform(X_val_fold1)\n",
    "X_test_scaled_fold1 = scaler_fold1.transform(X_test_fold1)\n",
    "\n",
    "# Check the results (optional)\n",
    "print(\"Training set:\", X_train_fold1.shape, y_train_fold1.shape)\n",
    "print(\"Testing set:\", X_test_fold1.shape, y_test_fold1.shape)\n",
    "print(\"Validation set:\", X_val_fold1.shape, y_val_fold1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b3603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting the validation and test sets\n",
    "train_dates_fold1 = data['T'].iloc[X_train_fold1.index] \n",
    "\n",
    "test_dates_fold1 = data['T'].iloc[X_test_fold1.index]     \n",
    "\n",
    "val_dates_fold1 = data['T'].iloc[X_val_fold1.index]     \n",
    "\n",
    "# Print the first few dates to check after the swap\n",
    "print(\"Training Dates:\\n\", train_dates_fold1)\n",
    "\n",
    "print(\"\\nTesting Dates:\\n\", test_dates_fold1)\n",
    "\n",
    "print(\"\\nValidation Dates:\\n\", val_dates_fold1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbab139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot the training, testing, and validation data for Fold1\n",
    "Tim = data['T']\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot training data\n",
    "plt.plot(Tim.iloc[X_train_fold1.index], y_train_fold1, 'g', label='Training')\n",
    "\n",
    "# Plot testing data (which comes after training)\n",
    "plt.plot(Tim.iloc[X_test_fold1.index], y_test_fold1, 'b', label='Testing')\n",
    "\n",
    "# Plot validation data (which comes after testing)\n",
    "plt.plot(Tim.iloc[X_val_fold1.index], y_val_fold1, 'r', label='Validation')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.ylabel('Water Level (WL_Mop)')\n",
    "plt.legend(fontsize=8)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bea2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the NSE function\n",
    "def nse(y_true, y_pred):\n",
    "    return 1 - (np.sum((y_true - y_pred) ** 2) / np.sum((y_true - np.mean(y_true)) ** 2))\n",
    "\n",
    "# Function to train the model with predefined hyperparameters and evaluate using NSE on both validation and test sets\n",
    "def train_and_evaluate(model, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and NSE for validation set\n",
    "    val_pred = model.predict(X_val)\n",
    "    val_nse = nse(y_val, val_pred)\n",
    "    \n",
    "    # Predictions and NSE for test set\n",
    "    test_pred = model.predict(X_test)\n",
    "    test_nse = nse(y_test, test_pred)\n",
    "    \n",
    "    return model, val_nse, test_nse\n",
    "\n",
    "# Best parameters for each model\n",
    "rf_params = {\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 3,\n",
    "    'min_samples_leaf': 3\n",
    "}\n",
    "\n",
    "gb_params = {\n",
    "    'n_estimators': 104,\n",
    "    'learning_rate': 0.06308188348933369,\n",
    "    'max_depth': 3,\n",
    "    'subsample': 0.721266023411284\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': 0.1,\n",
    "    'epsilon': 0.09393301263712334,\n",
    "    'gamma': 0.09783812402611333\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.05103704917722505,\n",
    "    'max_depth': 9,\n",
    "    'subsample': 0.8782745247955278,\n",
    "    'colsample_bytree': 0.6\n",
    "}\n",
    "\n",
    "# Instantiate models with the best hyperparameters\n",
    "models_fold1 = {\n",
    "    'RandomForest': RandomForestRegressor(**rf_params),\n",
    "    'GradientBoosting': GradientBoostingRegressor(**gb_params),\n",
    "    'SVM': SVR(**svm_params),\n",
    "    'XGB': XGBRegressor(**xgb_params)\n",
    "}\n",
    "\n",
    "# Train and evaluate models using the NSE metric on both validation and test sets\n",
    "results_fold1 = {}\n",
    "for model_name, model in models_fold1.items():\n",
    "    trained_model, val_nse, test_nse = train_and_evaluate(\n",
    "        model, X_train_scaled_fold1, y_train_fold1, X_val_scaled_fold1, y_val_fold1, X_test_scaled_fold1, y_test_fold1\n",
    "    )\n",
    "    results_fold1[model_name] = {\n",
    "        'Model': trained_model,\n",
    "        'NSE_Val': val_nse,\n",
    "        'NSE_Test': test_nse\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "for model_name, result in results_fold1.items():\n",
    "    print(f\"{model_name} - NSE Validation Score: {result['NSE_Val']:.2f}, NSE Test Score: {result['NSE_Test']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeed783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the evaluation function to calculate RMSE, MAPE, MAE, NSE, and R²\n",
    "def evaluate_model(model, X, y):\n",
    "    predictions = model.predict(X)\n",
    "    rmse = mean_squared_error(y, predictions, squared=False)  # Root Mean Squared Error\n",
    "    mae = mean_absolute_error(y, predictions)                 # Mean Absolute Error\n",
    "    mape = mean_absolute_percentage_error(y, predictions)     # Mean Absolute Percentage Error\n",
    "    r2 = r2_score(y, predictions)                             # R² Score\n",
    "    nse = 1 - (mean_squared_error(y, predictions) / mean_squared_error(y, [y.mean()]*len(y)))  # Nash-Sutcliffe Efficiency\n",
    "    return {'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'NSE': nse, 'R²': r2}\n",
    "\n",
    "# Evaluate the models on the test set\n",
    "test_metrics_fold1 = {name: evaluate_model(model, X_test_scaled_fold1, y_test_fold1) for name, model in models_fold1.items()}\n",
    "\n",
    "# Evaluate the models on the validation set\n",
    "val_metrics_fold1 = {name: evaluate_model(model, X_val_scaled_fold1, y_val_fold1) for name, model in models_fold1.items()}\n",
    "\n",
    "# Convert the results into DataFrames for easier visualization\n",
    "test_metrics_df_fold1 = pd.DataFrame(test_metrics_fold1).T\n",
    "val_metrics_df_fold1 = pd.DataFrame(val_metrics_fold1).T\n",
    "\n",
    "# Combine both test and validation metrics into a single DataFrame\n",
    "combined_metrics_df_fold1 = pd.concat([test_metrics_df_fold1.add_suffix('_Test'), val_metrics_df_fold1.add_suffix('_Val')], axis=1)\n",
    "\n",
    "# Display the combined metrics\n",
    "print(combined_metrics_df_fold1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e508eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "# Plot observed vs. predicted values for test and validation sets\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(16, 10), sharey=True)\n",
    "new_titles = ['(a)', '(b)', '(c)', '(d)', '(e)', '(f)', '(g)', '(h)']\n",
    "model_titles = ['RF', 'GB', 'SVM', 'XGB']\n",
    "\n",
    "# Loop over models and plot for both test and validation sets\n",
    "for i, (model_name, model) in enumerate(models_fold1.items()):\n",
    "    # Test set plot (first row)\n",
    "    ax_test = axes[0, i]\n",
    "    test_predictions = model.predict(X_test_scaled_fold1)\n",
    "    ax_test.scatter(y_test_fold1, test_predictions, alpha=0.4, color='blue', marker='o', s=10)\n",
    "    ax_test.plot([y_test_fold1.min(), y_test_fold1.max()], [y_test_fold1.min(), y_test_fold1.max()], 'r--', lw=2)\n",
    "    r2_test = r2_score(y_test_fold1, test_predictions)\n",
    "    ax_test.text(0.95, 0.05, new_titles[i], horizontalalignment='right', verticalalignment='bottom', transform=ax_test.transAxes, fontsize=16, color='black')\n",
    "    ax_test.text(0.05, 0.95, f'R²={r2_test:.2f}', transform=ax_test.transAxes, verticalalignment='top', color='blue', fontsize=16)\n",
    "    ax_test.set_title(f'{model_titles[i]}', fontsize=16)\n",
    "    if i == 0:\n",
    "        ax_test.set_ylabel('Predicted water level (m)', fontsize=16)\n",
    "\n",
    "    # Validation set plot (second row)\n",
    "    ax_val = axes[1, i]\n",
    "    val_predictions = model.predict(X_val_scaled_fold1)\n",
    "    ax_val.scatter(y_val_fold1, val_predictions, alpha=0.4, color='black', marker='o', s=10)\n",
    "    ax_val.plot([y_val_fold1.min(), y_val_fold1.max()], [y_val_fold1.min(), y_val_fold1.max()], 'r--', lw=2)\n",
    "    r2_val = r2_score(y_val_fold1, val_predictions)\n",
    "    ax_val.text(0.95, 0.05, new_titles[i + 4], horizontalalignment='right', verticalalignment='bottom', transform=ax_val.transAxes, fontsize=16, color='black')\n",
    "    ax_val.text(0.05, 0.95, f'R²={r2_val:.2f}', transform=ax_val.transAxes, verticalalignment='top', color='black', fontsize=16)\n",
    "    ax_val.set_xlabel('Observed water level (m)', fontsize=16)\n",
    "    if i == 0:\n",
    "        ax_val.set_ylabel('Predicted water level (m)', fontsize=16)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.savefig(\"Observed_vs_Predicted_Test_Validation_Separate_Panels_Fold1.png\", format='png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Plot evaluation metrics\n",
    "import numpy as np\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Define a function to format the ticks to one decimal place\n",
    "def one_decimal(x, pos):\n",
    "    return f'{x:.1f}'\n",
    "\n",
    "# Example metrics for bar plots\n",
    "models = ['RF', 'GB', 'SVM', 'XGB']\n",
    "bar_width = 0.35\n",
    "rmse_test = combined_metrics_df_fold1['RMSE_Test']\n",
    "rmse_val = combined_metrics_df_fold1['RMSE_Val']\n",
    "mae_test = combined_metrics_df_fold1['MAE_Test']\n",
    "mae_val = combined_metrics_df_fold1['MAE_Val']\n",
    "mape_test = combined_metrics_df_fold1['MAPE_Test']\n",
    "mape_val = combined_metrics_df_fold1['MAPE_Val']\n",
    "nse_test = combined_metrics_df_fold1['NSE_Test']\n",
    "nse_val = combined_metrics_df_fold1['NSE_Val']\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "fig, axs = plt.subplots(1, 4, figsize=(14, 4))\n",
    "\n",
    "# RMSE Bar Chart\n",
    "axs[0].bar(np.arange(len(models)), rmse_test, color='blue', width=bar_width, label='Test')\n",
    "axs[0].bar(np.arange(len(models)) + bar_width, rmse_val, color='black', width=bar_width, label='Val')\n",
    "axs[0].set_ylabel('RMSE (m)')\n",
    "axs[0].set_ylim(0.8, 1.8)\n",
    "axs[0].set_xticks(np.arange(len(models)) + bar_width / 2)\n",
    "axs[0].set_xticklabels(models)\n",
    "axs[0].text(0.95, 0.95, '(i)', transform=axs[0].transAxes, verticalalignment='top', horizontalalignment='right')\n",
    "axs[0].legend(loc='upper left', ncol=2, fontsize=10)\n",
    "\n",
    "# MAE Bar Chart\n",
    "axs[1].bar(np.arange(len(models)), mae_test, color='blue', width=bar_width, label='Test')\n",
    "axs[1].bar(np.arange(len(models)) + bar_width, mae_val, color='black', width=bar_width, label='Val')\n",
    "axs[1].set_ylabel('MAE (m)')\n",
    "axs[1].set_ylim(0.6, 1.15)\n",
    "axs[1].set_xticks(np.arange(len(models)) + bar_width / 2)\n",
    "axs[1].set_xticklabels(models)\n",
    "axs[1].text(0.95, 0.95, '(j)', transform=axs[1].transAxes, verticalalignment='top', horizontalalignment='right')\n",
    "\n",
    "# MAPE Bar Chart\n",
    "axs[2].bar(np.arange(len(models)), mape_test, color='blue', width=bar_width, label='Test')\n",
    "axs[2].bar(np.arange(len(models)) + bar_width, mape_val, color='black', width=bar_width, label='Val')\n",
    "axs[2].set_ylabel('MAPE')\n",
    "axs[2].set_ylim(0.4, 0.82)\n",
    "axs[2].yaxis.set_major_formatter(FuncFormatter(one_decimal))\n",
    "axs[2].set_xticks(np.arange(len(models)) + bar_width / 2)\n",
    "axs[2].set_xticklabels(models)\n",
    "axs[2].text(0.95, 0.95, '(k)', transform=axs[2].transAxes, verticalalignment='top', horizontalalignment='right')\n",
    "\n",
    "# NSE Bar Chart\n",
    "axs[3].bar(np.arange(len(models)), nse_test, color='blue', width=bar_width, label='Test')\n",
    "axs[3].bar(np.arange(len(models)) + bar_width, nse_val, color='black', width=bar_width, label='Val')\n",
    "axs[3].set_ylabel('NSE')\n",
    "axs[3].set_ylim(0.3, 0.8)\n",
    "axs[3].yaxis.set_major_formatter(FuncFormatter(one_decimal))\n",
    "axs[3].set_xticks(np.arange(len(models)) + bar_width / 2)\n",
    "axs[3].set_xticklabels(models)\n",
    "axs[3].text(0.95, 0.95, '(l)', transform=axs[3].transAxes, verticalalignment='top', horizontalalignment='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Metrics_Test_Val_Combined_Fold1.png\", format='png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc04999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the feature names based on your input features\n",
    "feature_names = X_fold1.columns\n",
    "\n",
    "# Setup the plotting for feature importance\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 3), sharey=True)\n",
    "\n",
    "new_titles = ['(m)', '(n)', '(o)']\n",
    "model_titles = ['RF', 'GB', 'XGB']\n",
    "\n",
    "# Plot feature importance for each model for validation set\n",
    "model_idx = 0\n",
    "\n",
    "for model_name, model in models_fold1.items():\n",
    "    if model_name in ['RandomForest', 'GradientBoosting', 'XGB']:\n",
    "        feature_importance = model.feature_importances_\n",
    "        ax_val = axes[model_idx]\n",
    "        ax_val.barh(feature_names, feature_importance, color='blue')\n",
    "        ax_val.set_title(f'{model_titles[model_idx]}', fontsize=16)\n",
    "        ax_val.text(0.95, 0.95, new_titles[model_idx], transform=ax_val.transAxes, fontsize=16, ha='right', va='top')\n",
    "        model_idx += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Feature_Importance_fold1.png\", format='png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b9805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the comparison DataFrame for the test set with dates, observed values, and predicted values\n",
    "df1_comparison_test = pd.DataFrame({\n",
    "    'Date': data['T'].iloc[X_test_fold1.index],  # The Date column based on the test set\n",
    "    'Observed': y_test_fold1,  # The observed values (ground truth)\n",
    "    'Predicted SVM': models_fold1['SVM'].predict(X_test_scaled_fold1),  # Predictions from SVM model\n",
    "    'Predicted RF': models_fold1['RandomForest'].predict(X_test_scaled_fold1),  # Predictions from Random Forest\n",
    "    'Predicted XGB': models_fold1['XGB'].predict(X_test_scaled_fold1),  # Predictions from XGBoost\n",
    "    'Predicted GB': models_fold1['GradientBoosting'].predict(X_test_scaled_fold1)  # Predictions from Gradient Boosting\n",
    "})\n",
    "\n",
    "# Create the comparison DataFrame for the validation set with dates, observed values, and predicted values\n",
    "df1_comparison_val = pd.DataFrame({\n",
    "    'Date': data['T'].iloc[X_val_fold1.index],  # The Date column based on the validation set\n",
    "    'Observed': y_val_fold1,  # The observed values (ground truth)\n",
    "    'Predicted SVM': models_fold1['SVM'].predict(X_val_scaled_fold1),  # Predictions from SVM model\n",
    "    'Predicted RF': models_fold1['RandomForest'].predict(X_val_scaled_fold1),  # Predictions from Random Forest\n",
    "    'Predicted XGB': models_fold1['XGB'].predict(X_val_scaled_fold1),  # Predictions from XGBoost\n",
    "    'Predicted GB': models_fold1['GradientBoosting'].predict(X_val_scaled_fold1)  # Predictions from Gradient Boosting\n",
    "})\n",
    "\n",
    "# Display the comparison DataFrames\n",
    "print(\"Test Set Comparison:\\n\", df1_comparison_test.head())\n",
    "print(\"\\nValidation Set Comparison:\\n\", df1_comparison_val.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1844226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models and corresponding colors for plots\n",
    "models = ['RF', 'GB', 'SVM', 'XGB']\n",
    "colors = ['blue', 'green', 'red', 'purple']\n",
    "\n",
    "# Create a figure with a 4x2 grid layout (4 models, test and validation columns)\n",
    "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(12, 16), sharey=True)\n",
    "\n",
    "# Loop over each model and create the corresponding plot for test (left column) and validation (right column)\n",
    "for idx, model in enumerate(models):\n",
    "    # Test set (first column)\n",
    "    axes[idx, 0].plot(df1_comparison_test['Date'], df1_comparison_test['Observed'], label='Observed', color='black', linestyle='-', linewidth=1.5)\n",
    "    axes[idx, 0].plot(df1_comparison_test['Date'], df1_comparison_test[f'Predicted {model}'], label=f'{model}', color=colors[idx], linestyle='-', linewidth=1.5)\n",
    "    \n",
    "    # Set limits for test set plot\n",
    "    axes[idx, 0].set_xlim([df1_comparison_test['Date'].min(), df1_comparison_test['Date'].max()])  # Limit to test dataset only\n",
    "    axes[idx, 0].set_ylim(0, 7.5)\n",
    "    axes[idx, 0].set_title(f'Test - {model}', fontsize=14)\n",
    "\n",
    "    # Set y-axis label for the first column\n",
    "    axes[idx, 0].set_ylabel('Water Level (m)', fontsize=14)\n",
    "    \n",
    "    # Remove x-ticks for all except the last test plot\n",
    "    if idx < 3:\n",
    "        axes[idx, 0].tick_params(axis='x', which='both', bottom=False, labelbottom=False)\n",
    "\n",
    "    # Rotate x-axis dates by 45 degrees for the last test plot only\n",
    "    if idx == 3:\n",
    "        axes[idx, 0].tick_params(axis='x', labelrotation=45)\n",
    "\n",
    "    # Add legend for test set\n",
    "    axes[idx, 0].legend(loc='upper left', fontsize=14, framealpha=0, ncol=2)\n",
    "    \n",
    "    # Annotate each subplot (test)\n",
    "    axes[idx, 0].annotate(f'(a{idx + 1})', xy=(0.95, 0.95), xycoords='axes fraction', fontsize=14, ha='right', va='top')\n",
    "\n",
    "    # Validation set (second column)\n",
    "    axes[idx, 1].plot(df1_comparison_val['Date'], df1_comparison_val['Observed'], label='Observed', color='black', linestyle='-', linewidth=1.5)\n",
    "    axes[idx, 1].plot(df1_comparison_val['Date'], df1_comparison_val[f'Predicted {model}'], label=f'{model}', color=colors[idx], linestyle='-', linewidth=1.5)\n",
    "    \n",
    "    # Set limits for validation set plot\n",
    "    axes[idx, 1].set_xlim([df1_comparison_val['Date'].min(), df1_comparison_val['Date'].max()])  # Limit to validation dataset only\n",
    "    axes[idx, 1].set_ylim(0, 7.5)\n",
    "    axes[idx, 1].set_title(f'Validation - {model}', fontsize=14)\n",
    "\n",
    "    # Remove x-ticks for all except the last validation plot\n",
    "    if idx < 3:\n",
    "        axes[idx, 1].tick_params(axis='x', which='both', bottom=False, labelbottom=False)\n",
    "\n",
    "    # Rotate x-axis dates by 45 degrees for the last validation plot only\n",
    "    if idx == 3:\n",
    "        axes[idx, 1].tick_params(axis='x', labelrotation=45)\n",
    "\n",
    "    # Add legend for validation set\n",
    "    axes[idx, 1].legend(loc='upper left', fontsize=14, framealpha=0, ncol=2)\n",
    "    \n",
    "    # Annotate each subplot (validation)\n",
    "    axes[idx, 1].annotate(f'(b{idx + 1})', xy=(0.95, 0.95), xycoords='axes fraction', fontsize=14, ha='right', va='top')\n",
    "\n",
    "# Adjust layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a high-resolution PNG file\n",
    "plt.savefig(\"Observed_vs_Predicted_Test_Validation_Panel_fold1.png\", format='png', dpi=300)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10622958",
   "metadata": {},
   "source": [
    "# CV FOLD 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05632213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y for fold2\n",
    "X_fold2 = data[['Tot_evap', 'WL_Sof', 'WL_Bou', 'WL_Pank', 'P', 'WL_Dou', 'WTD']]  # Inputs\n",
    "y_fold2 = data['WL_Mop']  # Target\n",
    "\n",
    "# Split the data: first 20% testing, middle 60% training, last 20% validation\n",
    "train_size_fold2 = int(0.6 * len(X_fold2))\n",
    "test_size_fold2 = int(0.2 * len(X_fold2))\n",
    "\n",
    "# The first 20% for testing\n",
    "X_test_fold2 = X_fold2.iloc[:test_size_fold2]\n",
    "y_test_fold2 = y_fold2.iloc[:test_size_fold2]\n",
    "\n",
    "# The middle 60% for training\n",
    "X_train_fold2 = X_fold2.iloc[test_size_fold2:test_size_fold2 + train_size_fold2]\n",
    "y_train_fold2 = y_fold2.iloc[test_size_fold2:test_size_fold2 + train_size_fold2]\n",
    "\n",
    "# The last 20% for validation\n",
    "X_val_fold2 = X_fold2.iloc[test_size_fold2 + train_size_fold2:]\n",
    "y_val_fold2 = y_fold2.iloc[test_size_fold2 + train_size_fold2:]\n",
    "\n",
    "# Scale the data\n",
    "scaler_fold2 = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform all datasets\n",
    "X_train_scaled_fold2 = scaler_fold2.fit_transform(X_train_fold2)\n",
    "X_val_scaled_fold2 = scaler_fold2.transform(X_val_fold2)\n",
    "X_test_scaled_fold2 = scaler_fold2.transform(X_test_fold2)\n",
    "\n",
    "# Correcting the validation and test sets\n",
    "train_dates_fold2 = data['T'].iloc[X_train_fold2.index]\n",
    "test_dates_fold2 = data['T'].iloc[X_test_fold2.index]\n",
    "val_dates_fold2 = data['T'].iloc[X_val_fold2.index]\n",
    "\n",
    "# Print the first few dates to check after the swap\n",
    "print(\"Training Dates:\\n\", train_dates_fold2)\n",
    "print(\"\\nTesting Dates:\\n\", test_dates_fold2)\n",
    "print(\"\\nValidation Dates:\\n\", val_dates_fold2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d55b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training, testing, and validation data\n",
    "Tim = data['T']\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot training data\n",
    "plt.plot(Tim.iloc[X_train_fold2.index], y_train_fold2, 'g', label='Training')\n",
    "\n",
    "# Plot testing data (which comes after training)\n",
    "plt.plot(Tim.iloc[X_test_fold2.index], y_test_fold2, 'b', label='Testing')\n",
    "\n",
    "# Plot validation data (which comes after testing)\n",
    "plt.plot(Tim.iloc[X_val_fold2.index], y_val_fold2, 'r', label='Validation')\n",
    "\n",
    "plt.ylabel('Water Level (WL_Mop)')\n",
    "plt.legend(fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d007d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the best hyperparameters for each model\n",
    "best_hyperparams = {\n",
    "    'RF': {\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 16,\n",
    "        'min_samples_split': 8,\n",
    "        'min_samples_leaf': 1\n",
    "    },\n",
    "    'GB': {\n",
    "        'n_estimators': 181,\n",
    "        'learning_rate': 0.01171817739833397,\n",
    "        'max_depth': 3,\n",
    "        'subsample': 0.6\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': 328.3163943534423,\n",
    "        'epsilon': 0.01,\n",
    "        'gamma': 0.002132966718896371\n",
    "    },\n",
    "    'XGB': {\n",
    "        'n_estimators': 121,\n",
    "        'learning_rate': 0.03925201734171761,\n",
    "        'max_depth': 3,\n",
    "        'subsample': 1.0,\n",
    "        'colsample_bytree': 0.6\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define model instances with the best hyperparameters\n",
    "models = {\n",
    "    'RF': RandomForestRegressor(**best_hyperparams['RF']),\n",
    "    'GB': GradientBoostingRegressor(**best_hyperparams['GB']),\n",
    "    'SVM': SVR(**best_hyperparams['SVM']),\n",
    "    'XGB': XGBRegressor(**best_hyperparams['XGB'])\n",
    "}\n",
    "\n",
    "# Evaluate the models on the test and validation sets\n",
    "def evaluate_model(model, X, y):\n",
    "    predictions = model.predict(X)\n",
    "    rmse = mean_squared_error(y, predictions, squared=False)  # Root Mean Squared Error\n",
    "    mae = mean_absolute_error(y, predictions)                 # Mean Absolute Error\n",
    "    mape = mean_absolute_percentage_error(y, predictions)     # Mean Absolute Percentage Error\n",
    "    r2 = r2_score(y, predictions)                             # R² Score\n",
    "    nse_score = nse(y, predictions)                           # Nash-Sutcliffe Efficiency\n",
    "    return {'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'NSE': nse_score, 'R²': r2}\n",
    "\n",
    "# Evaluate the models on both test and validation sets\n",
    "evaluation_results_test = {}\n",
    "evaluation_results_val = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled_fold2, y_train_fold2)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    evaluation_results_test[model_name] = evaluate_model(model, X_test_scaled_fold2, y_test_fold2)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    evaluation_results_val[model_name] = evaluate_model(model, X_val_scaled_fold2, y_val_fold2)\n",
    "\n",
    "# Print the evaluation results for the test set\n",
    "print(\"\\nEvaluation results for the Test Set:\")\n",
    "for model_name, result in evaluation_results_test.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for metric, value in result.items():\n",
    "        print(f\"{metric}: {value:.2f}\")\n",
    "\n",
    "# Print the evaluation results for the validation set\n",
    "print(\"\\nEvaluation results for the Validation Set:\")\n",
    "for model_name, result in evaluation_results_val.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for metric, value in result.items():\n",
    "        print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c62b6d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Update font size\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "# Create the subplots with a 2x4 grid layout (for 8 subplots total: 4 for test and 4 for validation)\n",
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(16, 10), sharey=True)\n",
    "\n",
    "# Define the titles for each subplot\n",
    "new_titles = ['(a)', '(b)', '(c)', '(d)', '(e)', '(f)', '(g)', '(h)']\n",
    "model_titles = ['RF', 'GB', 'SVM', 'XGB']  # Titles for each model\n",
    "\n",
    "# Fit each model before making predictions\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_scaled_fold2, y_train_fold2)  # Train the model on training data\n",
    "\n",
    "# Loop over models and plot for both test and validation sets in separate panels\n",
    "for i, (model_name, model) in enumerate(models.items()):\n",
    "    # Test set plot (first row)\n",
    "    ax_test = axes[0, i]\n",
    "    test_predictions = model.predict(X_test_scaled_fold2)\n",
    "    \n",
    "    # Scatter plot of observed vs predicted values for test set\n",
    "    ax_test.scatter(y_test_fold2, test_predictions, alpha=0.4, color='blue', marker='o', s=10)\n",
    "    ax_test.plot([y_test_fold2.min(), y_test_fold2.max()], [y_test_fold2.min(), y_test_fold2.max()], 'r--', lw=2)  # Line for perfect predictions\n",
    "\n",
    "    # Add R² score for test set\n",
    "    r2_test = r2_score(y_test_fold2, test_predictions)\n",
    "    ax_test.text(0.95, 0.05, new_titles[i], horizontalalignment='right', verticalalignment='bottom', transform=ax_test.transAxes, fontsize=16, color='black')\n",
    "    ax_test.text(0.05, 0.95, f'R²={r2_test:.2f}', transform=ax_test.transAxes, verticalalignment='top', color='blue', fontsize=16)\n",
    "\n",
    "    # Set labels and title for each test subplot\n",
    "    ax_test.set_title(f'{model_titles[i]}', fontsize=16)\n",
    "    if i == 0:\n",
    "        ax_test.set_ylabel('Predicted water level (m)', fontsize=16)\n",
    "\n",
    "    # Validation set plot (second row)\n",
    "    ax_val = axes[1, i]\n",
    "    val_predictions = model.predict(X_val_scaled_fold2)\n",
    "    \n",
    "    # Scatter plot of observed vs predicted values for validation set\n",
    "    ax_val.scatter(y_val_fold2, val_predictions, alpha=0.4, color='black', marker='o', s=10)\n",
    "    ax_val.plot([y_val_fold2.min(), y_val_fold2.max()], [y_val_fold2.min(), y_val_fold2.max()], 'r--', lw=2)  # Line for perfect predictions\n",
    "\n",
    "    # Add R² score for validation set\n",
    "    r2_val = r2_score(y_val_fold2, val_predictions)\n",
    "    ax_val.text(0.95, 0.05, new_titles[i + 4], horizontalalignment='right', verticalalignment='bottom', transform=ax_val.transAxes, fontsize=16, color='black')\n",
    "    ax_val.text(0.05, 0.95, f'R²={r2_val:.2f}', transform=ax_val.transAxes, verticalalignment='top', color='black', fontsize=16)\n",
    "\n",
    "    # Set labels and title for each validation subplot\n",
    "    ax_val.set_xlabel('Observed water level (m)', fontsize=16)\n",
    "    if i == 0:\n",
    "        ax_val.set_ylabel('Predicted water level (m)', fontsize=16)\n",
    "\n",
    "# Adjust layout to avoid overlap\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Add space for the suptitle\n",
    "\n",
    "# Save the figure with 300 DPI\n",
    "plt.savefig(\"Observed_vs_Predicted_Test_Validation_Separate_Panels_Fold2.png\", format='png', dpi=300)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Define the models and their evaluation results from your table\n",
    "models = ['RF', 'GB', 'SVM', 'XGB']\n",
    "bar_width = 0.35\n",
    "\n",
    "# Test Set results (from your table)\n",
    "rmse_test = [0.39, 0.46, 0.37, 0.38]\n",
    "mae_test = [0.31, 0.40, 0.28, 0.31]\n",
    "mape_test = [0.24, 0.36, 0.20, 0.24]\n",
    "nse_test = [0.93, 0.91, 0.94, 0.94]\n",
    "\n",
    "# Validation Set results (from your table)\n",
    "rmse_val = [0.41, 0.66, 0.52, 0.54]\n",
    "mae_val = [0.31, 0.54, 0.41, 0.42]\n",
    "mape_val = [0.20, 0.36, 0.29, 0.27]\n",
    "nse_val = [0.96, 0.90, 0.94, 0.93]\n",
    "\n",
    "# Define a function to format ticks to one decimal place\n",
    "def one_decimal(x, pos):\n",
    "    return f'{x:.1f}'\n",
    "\n",
    "# Create a subplot grid of 1x4 for RMSE, MAE, MAPE, and NSE (test and val combined)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 4))\n",
    "\n",
    "# RMSE Bar Chart (Test and Val combined)\n",
    "axs[0].bar(np.arange(len(models)), rmse_test, color='blue', width=bar_width, label='Test')\n",
    "axs[0].bar(np.arange(len(models)) + bar_width, rmse_val, color='black', width=bar_width, label='Val')\n",
    "axs[0].set_ylabel('RMSE (m)')\n",
    "axs[0].set_ylim(0.3, 0.75)  # Adjust the y-axis range based on the RMSE values\n",
    "axs[0].set_xticks(np.arange(len(models)) + bar_width / 2)\n",
    "axs[0].set_xticklabels(models)\n",
    "axs[0].text(0.95, 0.95, '(i)', transform=axs[0].transAxes, verticalalignment='top', horizontalalignment='right')\n",
    "axs[0].legend(loc='upper left', ncol=2, fontsize=10)\n",
    "\n",
    "# MAE Bar Chart (Test and Val combined)\n",
    "axs[1].bar(np.arange(len(models)), mae_test, color='blue', width=bar_width, label='Test')\n",
    "axs[1].bar(np.arange(len(models)) + bar_width, mae_val, color='black', width=bar_width, label='Val')\n",
    "axs[1].set_ylabel('MAE (m)')\n",
    "axs[1].set_ylim(0.2, 0.6)  # Adjust the y-axis range based on the MAE values\n",
    "axs[1].set_xticks(np.arange(len(models)) + bar_width / 2)\n",
    "axs[1].set_xticklabels(models)\n",
    "axs[1].text(0.95, 0.95, '(j)', transform=axs[1].transAxes, verticalalignment='top', horizontalalignment='right')\n",
    "\n",
    "# MAPE Bar Chart (Test and Val combined)\n",
    "axs[2].bar(np.arange(len(models)), mape_test, color='blue', width=bar_width, label='Test')\n",
    "axs[2].bar(np.arange(len(models)) + bar_width, mape_val, color='black', width=bar_width, label='Val')\n",
    "axs[2].set_ylabel('MAPE')\n",
    "axs[2].set_ylim(0.1, 0.4)  # Adjust the y-axis range based on the MAPE values\n",
    "axs[2].yaxis.set_major_formatter(FuncFormatter(one_decimal))\n",
    "axs[2].set_xticks(np.arange(len(models)) + bar_width / 2)\n",
    "axs[2].set_xticklabels(models)\n",
    "axs[2].text(0.95, 0.95, '(k)', transform=axs[2].transAxes, verticalalignment='top', horizontalalignment='right')\n",
    "\n",
    "# NSE Bar Chart (Test and Val combined)\n",
    "axs[3].bar(np.arange(len(models)), nse_test, color='blue', width=bar_width, label='Test')\n",
    "axs[3].bar(np.arange(len(models)) + bar_width, nse_val, color='black', width=bar_width, label='Val')\n",
    "axs[3].set_ylabel('NSE')\n",
    "axs[3].set_ylim(0.7, 1)  # Adjust the y-axis range based on the NSE values\n",
    "axs[3].yaxis.set_major_formatter(FuncFormatter(one_decimal))\n",
    "axs[3].set_xticks(np.arange(len(models)) + bar_width / 2)\n",
    "axs[3].set_xticklabels(models)\n",
    "axs[3].text(0.95, 0.95, '(l)', transform=axs[3].transAxes, verticalalignment='top', horizontalalignment='right')\n",
    "\n",
    "# Adjust the layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Metrics_Test_Val_Combined_Fold2.png\", format='png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de32d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define the models based on provided best hyperparameters\n",
    "models_fold1 = {\n",
    "    'RF': RandomForestRegressor(n_estimators=100, max_depth=16, min_samples_split=8, min_samples_leaf=1),\n",
    "    'GB': GradientBoostingRegressor(n_estimators=181, learning_rate=0.01171817739833397, max_depth=3, subsample=0.6),\n",
    "    'XGB': XGBRegressor(n_estimators=121, learning_rate=0.03925201734171761, max_depth=3, subsample=1.0, colsample_bytree=0.6)\n",
    "}\n",
    "\n",
    "# Fit models and collect feature importances\n",
    "feature_importances = {}\n",
    "for model_name, model in models_fold1.items():\n",
    "    model.fit(X_train_scaled_fold2, y_train_fold2)  # Train each model\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        feature_importances[model_name] = model.feature_importances_\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "# Setup for plotting\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 3), sharey=True)\n",
    "new_titles = ['(m)', '(n)', '(o)']\n",
    "model_titles = ['RF', 'GB', 'XGB']\n",
    "\n",
    "# Plot feature importance for each model\n",
    "model_idx = 0\n",
    "for model_name, importances in feature_importances.items():\n",
    "    ax = axes[model_idx]\n",
    "    ax.barh(X_train_fold2.columns, importances, color='blue')\n",
    "    ax.set_title(model_titles[model_idx], fontsize=12)\n",
    "    ax.text(0.95, 0.95, new_titles[model_idx], transform=ax.transAxes, fontsize=12, ha='right', va='top')\n",
    "    model_idx += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Feature_Importance_fold2.png\", format='png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d2d2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'RF': RandomForestRegressor(**best_hyperparams['RF']),\n",
    "    'GB': GradientBoostingRegressor(**best_hyperparams['GB']),\n",
    "    'SVM': SVR(**best_hyperparams['SVM']),\n",
    "    'XGB': XGBRegressor(**best_hyperparams['XGB'])\n",
    "}\n",
    "\n",
    "# Fit all models on the training data\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_scaled_fold2, y_train_fold2)  # Ensure all models are trained\n",
    "\n",
    "# Create the comparison DataFrame for the test set with dates, observed values, and predicted values\n",
    "df2_comparison_test = pd.DataFrame({\n",
    "    'Date': data['T'].iloc[X_test_fold2.index],  # The Date column based on the test set\n",
    "    'Observed': y_test_fold2,  # The observed values (ground truth)\n",
    "    'Predicted SVM': models['SVM'].predict(X_test_scaled_fold2),  # Predictions from SVM model\n",
    "    'Predicted RF': models['RF'].predict(X_test_scaled_fold2),  # Predictions from Random Forest\n",
    "    'Predicted XGB': models['XGB'].predict(X_test_scaled_fold2),  # Predictions from XGBoost\n",
    "    'Predicted GB': models['GB'].predict(X_test_scaled_fold2)  # Predictions from Gradient Boosting\n",
    "})\n",
    "\n",
    "# Create the comparison DataFrame for the validation set with dates, observed values, and predicted values\n",
    "df2_comparison_val = pd.DataFrame({\n",
    "    'Date': data['T'].iloc[X_val_fold2.index],  # The Date column based on the validation set\n",
    "    'Observed': y_val_fold2,  # The observed values (ground truth)\n",
    "    'Predicted SVM': models['SVM'].predict(X_val_scaled_fold2),  # Predictions from SVM model\n",
    "    'Predicted RF': models['RF'].predict(X_val_scaled_fold2),  # Predictions from Random Forest\n",
    "    'Predicted XGB': models['XGB'].predict(X_val_scaled_fold2),  # Predictions from XGBoost\n",
    "    'Predicted GB': models['GB'].predict(X_val_scaled_fold2)  # Predictions from Gradient Boosting\n",
    "})\n",
    "\n",
    "# Display the comparison DataFrames\n",
    "print(\"Test Set Comparison:\\n\", df2_comparison_test.head())\n",
    "print(\"\\nValidation Set Comparison:\\n\", df2_comparison_val.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede890dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models and corresponding colors for plots\n",
    "model_names = ['RF', 'GB', 'SVM', 'XGB']\n",
    "colors = ['blue', 'green', 'red', 'purple']\n",
    "\n",
    "# Create a figure with a 4x2 grid layout (4 models, test and validation columns)\n",
    "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(12, 16), sharey=True)\n",
    "\n",
    "# Loop over each model and create the corresponding plot for test (left column) and validation (right column)\n",
    "for idx, model in enumerate(model_names):\n",
    "    # Test set (first column)\n",
    "    axes[idx, 0].plot(df2_comparison_test['Date'], df2_comparison_test['Observed'], label='Observed', color='black', linestyle='-', linewidth=1.5)\n",
    "    axes[idx, 0].plot(df2_comparison_test['Date'], df2_comparison_test[f'Predicted {model}'], label=f'{model}', color=colors[idx], linestyle='-', linewidth=1.5)\n",
    "    \n",
    "    # Set limits for test set plot\n",
    "    axes[idx, 0].set_xlim([df2_comparison_test['Date'].min(), df2_comparison_test['Date'].max()])  # Limit to test dataset only\n",
    "    axes[idx, 0].set_ylim(0, 7.5)\n",
    "    axes[idx, 0].set_title(f'Test - {model}', fontsize=14)\n",
    "\n",
    "    # Set y-axis label for the first column\n",
    "    axes[idx, 0].set_ylabel('Water Level (m)', fontsize=14)\n",
    "    \n",
    "    # Remove x-ticks for all except the last test plot\n",
    "    if idx < 3:\n",
    "        axes[idx, 0].tick_params(axis='x', which='both', bottom=False, labelbottom=False)\n",
    "\n",
    "    # Rotate x-axis dates by 45 degrees for the last test plot only\n",
    "    if idx == 3:\n",
    "        axes[idx, 0].tick_params(axis='x', labelrotation=45)\n",
    "\n",
    "    # Add legend for test set\n",
    "    axes[idx, 0].legend(loc='upper left', fontsize=14, framealpha=0, ncol=2)\n",
    "    \n",
    "    # Annotate each subplot (test)\n",
    "    axes[idx, 0].annotate(f'(a{idx + 1})', xy=(0.95, 0.95), xycoords='axes fraction', fontsize=14, ha='right', va='top')\n",
    "\n",
    "    # Validation set (second column)\n",
    "    axes[idx, 1].plot(df2_comparison_val['Date'], df2_comparison_val['Observed'], label='Observed', color='black', linestyle='-', linewidth=1.5)\n",
    "    axes[idx, 1].plot(df2_comparison_val['Date'], df2_comparison_val[f'Predicted {model}'], label=f'{model}', color=colors[idx], linestyle='-', linewidth=1.5)\n",
    "    \n",
    "    # Set limits for validation set plot\n",
    "    axes[idx, 1].set_xlim([df2_comparison_val['Date'].min(), df2_comparison_val['Date'].max()])  # Limit to validation dataset only\n",
    "    axes[idx, 1].set_ylim(0, 7.5)\n",
    "    axes[idx, 1].set_title(f'Validation - {model}', fontsize=14)\n",
    "\n",
    "    # Remove x-ticks for all except the last validation plot\n",
    "    if idx < 3:\n",
    "        axes[idx, 1].tick_params(axis='x', which='both', bottom=False, labelbottom=False)\n",
    "\n",
    "    # Rotate x-axis dates by 45 degrees for the last validation plot only\n",
    "    if idx == 3:\n",
    "        axes[idx, 1].tick_params(axis='x', labelrotation=45)\n",
    "\n",
    "    # Add legend for validation set\n",
    "    axes[idx, 1].legend(loc='upper left', fontsize=14, framealpha=0, ncol=2)\n",
    "    \n",
    "    # Annotate each subplot (validation)\n",
    "    axes[idx, 1].annotate(f'(b{idx + 1})', xy=(0.95, 0.95), xycoords='axes fraction', fontsize=14, ha='right', va='top')\n",
    "\n",
    "# Adjust layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a high-resolution PNG file\n",
    "plt.savefig(\"Observed_vs_Predicted_Test_Validation_Panel_fold2.png\", format='png', dpi=300)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aff108",
   "metadata": {},
   "source": [
    "# End of CV process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200d3ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the panel for both fold1 and fold2 in a single figure\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 6))\n",
    "\n",
    "# Plot for fold1\n",
    "axes[0].plot(Tim.iloc[X_train_fold1.index], y_train_fold1, 'g', label='Training')\n",
    "axes[0].plot(Tim.iloc[X_test_fold1.index], y_test_fold1, 'b', label='Testing')\n",
    "axes[0].plot(Tim.iloc[X_val_fold1.index], y_val_fold1, 'black', label='Validation')\n",
    "axes[0].set_ylabel('Water Level (WL_Mop)')\n",
    "axes[0].legend(fontsize=8)\n",
    "axes[0].text(0.99, 0.99, '(a)', transform=axes[0].transAxes, verticalalignment='top', horizontalalignment='right', fontsize=14)\n",
    "\n",
    "# Plot for fold2\n",
    "axes[1].plot(Tim.iloc[X_train_fold2.index], y_train_fold2, 'g', label='Training')\n",
    "axes[1].plot(Tim.iloc[X_test_fold2.index], y_test_fold2, 'b', label='Testing')\n",
    "axes[1].plot(Tim.iloc[X_val_fold2.index], y_val_fold2, 'black', label='Validation')\n",
    "axes[1].set_ylabel('Water Level (WL_Mop)')\n",
    "axes[1].legend(fontsize=8)\n",
    "axes[1].text(0.99, 0.99, '(b)', transform=axes[1].transAxes, verticalalignment='top', horizontalalignment='right', fontsize=14)\n",
    "\n",
    "# Adjust layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"Training_Testing_Validation_Fold1_and_Fold2.png\", format='png', dpi=300)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2f8b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Set the font size for the whole plot\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "# Create a figure with 3 rows and 4 columns: 1st row for test scatter plots, 2nd row for validation scatter plots, 3rd row for bar plots\n",
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(16, 12))\n",
    "\n",
    "# Define the model names and their respective columns for scatter and bar plots\n",
    "model_titles = ['RF', 'GB', 'SVM', 'XGB']\n",
    "new_titles = ['(a)', '(b)', '(c)', '(d)', '(e)', '(f)', '(g)', '(h)']\n",
    "bar_titles = ['(i)', '(j)', '(k)', '(l)']\n",
    "\n",
    "# Plot observed vs predicted values for test and validation sets (first 2 rows)\n",
    "for i, (model_name, model) in enumerate(models_fold1.items()):\n",
    "    # Test set plot (first row)\n",
    "    ax_test = axes[0, i]\n",
    "    test_predictions = model.predict(X_test_scaled_fold1)\n",
    "    ax_test.scatter(y_test_fold1, test_predictions, alpha=0.4, color='blue', marker='o', s=10)\n",
    "    ax_test.plot([y_test_fold1.min(), y_test_fold1.max()], [y_test_fold1.min(), y_test_fold1.max()], 'r--', lw=2)\n",
    "    r2_test = r2_score(y_test_fold1, test_predictions)\n",
    "    ax_test.text(0.95, 0.05, new_titles[i], horizontalalignment='right', verticalalignment='bottom', transform=ax_test.transAxes, fontsize=16, color='black')\n",
    "    ax_test.text(0.05, 0.95, f'R²={r2_test:.2f}', transform=ax_test.transAxes, verticalalignment='top', color='blue', fontsize=16)\n",
    "    ax_test.set_title(f'{model_titles[i]}', fontsize=16)\n",
    "    if i == 0:\n",
    "        ax_test.set_ylabel('Predicted water level (m)', fontsize=16)\n",
    "\n",
    "    # Validation set plot (second row)\n",
    "    ax_val = axes[1, i]\n",
    "    val_predictions = model.predict(X_val_scaled_fold1)\n",
    "    ax_val.scatter(y_val_fold1, val_predictions, alpha=0.4, color='black', marker='o', s=10)\n",
    "    ax_val.plot([y_val_fold1.min(), y_val_fold1.max()], [y_val_fold1.min(), y_val_fold1.max()], 'r--', lw=2)\n",
    "    r2_val = r2_score(y_val_fold1, val_predictions)\n",
    "    ax_val.text(0.95, 0.05, new_titles[i + 4], horizontalalignment='right', verticalalignment='bottom', transform=ax_val.transAxes, fontsize=16, color='black')\n",
    "    ax_val.text(0.05, 0.95, f'R²={r2_val:.2f}', transform=ax_val.transAxes, verticalalignment='top', color='black', fontsize=16)\n",
    "    ax_val.set_xlabel('Observed water level (m)', fontsize=16)\n",
    "    if i == 0:\n",
    "        ax_val.set_ylabel('Predicted water level (m)', fontsize=16)\n",
    "\n",
    "# Plot evaluation metrics (third row)\n",
    "models = ['RF', 'GB', 'SVM', 'XGB']\n",
    "bar_width = 0.35\n",
    "\n",
    "# Values for bar plots (from your example)\n",
    "rmse_test = combined_metrics_df_fold1['RMSE_Test']\n",
    "rmse_val = combined_metrics_df_fold1['RMSE_Val']\n",
    "mae_test = combined_metrics_df_fold1['MAE_Test']\n",
    "mae_val = combined_metrics_df_fold1['MAE_Val']\n",
    "mape_test = combined_metrics_df_fold1['MAPE_Test']\n",
    "mape_val = combined_metrics_df_fold1['MAPE_Val']\n",
    "nse_test = combined_metrics_df_fold1['NSE_Test']\n",
    "nse_val = combined_metrics_df_fold1['NSE_Val']\n",
    "\n",
    "# RMSE Bar Chart (first column)\n",
    "axes[2, 0].bar(np.arange(len(models)), rmse_test, color='blue', width=bar_width, label='Test')\n",
    "axes[2, 0].bar(np.arange(len(models)) + bar_width, rmse_val, color='black', width=bar_width, label='Val')\n",
    "axes[2, 0].set_ylabel('RMSE (m)')\n",
    "axes[2, 0].set_ylim(0.8, 1.8)\n",
    "axes[2, 0].set_xticks(np.arange(len(models)) + bar_width / 2)\n",
    "axes[2, 0].set_xticklabels(models)\n",
    "axes[2, 0].text(0.95, 0.95, bar_titles[0], transform=axes[2, 0].transAxes, verticalalignment='top', horizontalalignment='right')\n",
    "axes[2, 0].legend(loc='upper left', ncol=2, fontsize=10)\n",
    "\n",
    "# MAE Bar Chart (second column)\n",
    "axes[2, 1].bar(np.arange(len(models)), mae_test, color='blue', width=bar_width, label='Test')\n",
    "axes[2, 1].bar(np.arange(len(models)) + bar_width, mae_val, color='black', width=bar_width, label='Val')\n",
    "axes[2, 1].set_ylabel('MAE (m)')\n",
    "axes[2, 1].set_ylim(0.6, 1.15)\n",
    "axes[2, 1].set_xticks(np.arange(len(models)) + bar_width / 2)\n",
    "axes[2, 1].set_xticklabels(models)\n",
    "axes[2, 1].text(0.95, 0.95, bar_titles[1], transform=axes[2, 1].transAxes, verticalalignment='top', horizontalalignment='right')\n",
    "\n",
    "# MAPE Bar Chart (third column)\n",
    "axes[2, 2].bar(np.arange(len(models)), mape_test, color='blue', width=bar_width, label='Test')\n",
    "axes[2, 2].bar(np.arange(len(models)) + bar_width, mape_val, color='black', width=bar_width, label='Val')\n",
    "axes[2, 2].set_ylabel('MAPE')\n",
    "axes[2, 2].set_ylim(0.4, 0.82)\n",
    "axes[2, 2].yaxis.set_major_formatter(FuncFormatter(one_decimal))\n",
    "axes[2, 2].set_xticks(np.arange(len(models)) + bar_width / 2)\n",
    "axes[2, 2].set_xticklabels(models)\n",
    "axes[2, 2].text(0.95, 0.95, bar_titles[2], transform=axes[2, 2].transAxes, verticalalignment='top', horizontalalignment='right')\n",
    "\n",
    "# NSE Bar Chart (fourth column)\n",
    "axes[2, 3].bar(np.arange(len(models)), nse_test, color='blue', width=bar_width, label='Test')\n",
    "axes[2, 3].bar(np.arange(len(models)) + bar_width, nse_val, color='black', width=bar_width, label='Val')\n",
    "axes[2, 3].set_ylabel('NSE')\n",
    "axes[2, 3].set_ylim(0.3, 0.8)\n",
    "axes[2, 3].yaxis.set_major_formatter(FuncFormatter(one_decimal))\n",
    "axes[2, 3].set_xticks(np.arange(len(models)) + bar_width / 2)\n",
    "axes[2, 3].set_xticklabels(models)\n",
    "axes[2, 3].text(0.95, 0.95, bar_titles[3], transform=axes[2, 3].transAxes, verticalalignment='top', horizontalalignment='right')\n",
    "\n",
    "# Adjust layout and show the final figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Combined_Scatter_Bar_Plots_Fold1.png\", format='png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad69298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Set the font size for the whole plot\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "# Create a figure with 3 rows and 4 columns: 1st row for test scatter plots, 2nd row for validation scatter plots, 3rd row for bar plots\n",
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(16, 12))\n",
    "\n",
    "# Define the model names and their respective columns for scatter and bar plots\n",
    "model_titles = ['RF', 'GB', 'SVM', 'XGB']\n",
    "new_titles = ['(a)', '(b)', '(c)', '(d)', '(e)', '(f)', '(g)', '(h)']\n",
    "bar_titles = ['(i)', '(j)', '(k)', '(l)']\n",
    "\n",
    "# Fit each model before making predictions\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_scaled_fold2, y_train_fold2)  # Train the model on training data\n",
    "\n",
    "# Plot observed vs. predicted values for test and validation sets (first 2 rows)\n",
    "for i, (model_name, model) in enumerate(models.items()):\n",
    "    # Test set plot (first row)\n",
    "    ax_test = axes[0, i]\n",
    "    test_predictions = model.predict(X_test_scaled_fold2)\n",
    "    ax_test.scatter(y_test_fold2, test_predictions, alpha=0.4, color='blue', marker='o', s=10)\n",
    "    ax_test.plot([y_test_fold2.min(), y_test_fold2.max()], [y_test_fold2.min(), y_test_fold2.max()], 'r--', lw=2)\n",
    "    r2_test = r2_score(y_test_fold2, test_predictions)\n",
    "    ax_test.text(0.95, 0.05, new_titles[i], horizontalalignment='right', verticalalignment='bottom', transform=ax_test.transAxes, fontsize=16, color='black')\n",
    "    ax_test.text(0.05, 0.95, f'R²={r2_test:.2f}', transform=ax_test.transAxes, verticalalignment='top', color='blue', fontsize=16)\n",
    "    ax_test.set_title(f'{model_titles[i]}', fontsize=16)\n",
    "    if i == 0:\n",
    "        ax_test.set_ylabel('Predicted water level (m)', fontsize=16)\n",
    "\n",
    "    # Validation set plot (second row)\n",
    "    ax_val = axes[1, i]\n",
    "    val_predictions = model.predict(X_val_scaled_fold2)\n",
    "    ax_val.scatter(y_val_fold2, val_predictions, alpha=0.4, color='black', marker='o', s=10)\n",
    "    ax_val.plot([y_val_fold2.min(), y_val_fold2.max()], [y_val_fold2.min(), y_val_fold2.max()], 'r--', lw=2)\n",
    "    r2_val = r2_score(y_val_fold2, val_predictions)\n",
    "    ax_val.text(0.95, 0.05, new_titles[i + 4], horizontalalignment='right', verticalalignment='bottom', transform=ax_val.transAxes, fontsize=16, color='black')\n",
    "    ax_val.text(0.05, 0.95, f'R²={r2_val:.2f}', transform=ax_val.transAxes, verticalalignment='top', color='black', fontsize=16)\n",
    "    ax_val.set_xlabel('Observed water level (m)', fontsize=16)\n",
    "    if i == 0:\n",
    "        ax_val.set_ylabel('Predicted water level (m)', fontsize=16)\n",
    "\n",
    "# Define the metrics for the bar plots\n",
    "models = ['RF', 'GB', 'SVM', 'XGB']\n",
    "bar_width = 0.35\n",
    "\n",
    "# Test Set results (from your example)\n",
    "rmse_test = [0.39, 0.46, 0.37, 0.38]\n",
    "mae_test = [0.31, 0.40, 0.28, 0.31]\n",
    "mape_test = [0.24, 0.36, 0.20, 0.24]\n",
    "nse_test = [0.93, 0.91, 0.94, 0.94]\n",
    "\n",
    "# Validation Set results (from your example)\n",
    "rmse_val = [0.41, 0.66, 0.52, 0.54]\n",
    "mae_val = [0.31, 0.54, 0.41, 0.42]\n",
    "mape_val = [0.20, 0.36, 0.29, 0.27]\n",
    "nse_val = [0.96, 0.90, 0.94, 0.93]\n",
    "\n",
    "# Define a function to format ticks to one decimal place\n",
    "def one_decimal(x, pos):\n",
    "    return f'{x:.1f}'\n",
    "\n",
    "# RMSE Bar Chart (first column)\n",
    "axes[2, 0].bar(np.arange(len(models)), rmse_test, color='blue', width=bar_width, label='Test')\n",
    "axes[2, 0].bar(np.arange(len(models)) + bar_width, rmse_val, color='black', width=bar_width, label='Val')\n",
    "axes[2, 0].set_ylabel('RMSE (m)')\n",
    "axes[2, 0].set_ylim(0.3, 0.75)  # Adjust the y-axis range based on the RMSE values\n",
    "axes[2, 0].set_xticks(np.arange(len(models)) + bar_width / 2)\n",
    "axes[2, 0].set_xticklabels(models)\n",
    "axes[2, 0].text(0.95, 0.95, bar_titles[0], transform=axes[2, 0].transAxes, verticalalignment='top', horizontalalignment='right')\n",
    "axes[2, 0].legend(loc='upper left', ncol=2, fontsize=10)\n",
    "\n",
    "# MAE Bar Chart (second column)\n",
    "axes[2, 1].bar(np.arange(len(models)), mae_test, color='blue', width=bar_width, label='Test')\n",
    "axes[2, 1].bar(np.arange(len(models)) + bar_width, mae_val, color='black', width=bar_width, label='Val')\n",
    "axes[2, 1].set_ylabel('MAE (m)')\n",
    "axes[2, 1].set_ylim(0.2, 0.6)  # Adjust the y-axis range based on the MAE values\n",
    "axes[2, 1].set_xticks(np.arange(len(models)) + bar_width / 2)\n",
    "axes[2, 1].set_xticklabels(models)\n",
    "axes[2, 1].text(0.95, 0.95, bar_titles[1], transform=axes[2, 1].transAxes, verticalalignment='top', horizontalalignment='right')\n",
    "\n",
    "# MAPE Bar Chart (third column)\n",
    "axes[2, 2].bar(np.arange(len(models)), mape_test, color='blue', width=bar_width, label='Test')\n",
    "axes[2, 2].bar(np.arange(len(models)) + bar_width, mape_val, color='black', width=bar_width, label='Val')\n",
    "axes[2, 2].set_ylabel('MAPE')\n",
    "axes[2, 2].set_ylim(0.1, 0.4)  # Adjust the y-axis range based on the MAPE values\n",
    "axes[2, 2].yaxis.set_major_formatter(FuncFormatter(one_decimal))\n",
    "axes[2, 2].set_xticks(np.arange(len(models)) + bar_width / 2)\n",
    "axes[2, 2].set_xticklabels(models)\n",
    "axes[2, 2].text(0.95, 0.95, bar_titles[2], transform=axes[2, 2].transAxes, verticalalignment='top', horizontalalignment='right')\n",
    "\n",
    "# NSE Bar Chart (fourth column)\n",
    "axes[2, 3].bar(np.arange(len(models)), nse_test, color='blue', width=bar_width, label='Test')\n",
    "axes[2, 3].bar(np.arange(len(models)) + bar_width, nse_val, color='black', width=bar_width, label='Val')\n",
    "axes[2, 3].set_ylabel('NSE')\n",
    "axes[2, 3].set_ylim(0.7, 1)  # Adjust the y-axis range based on the NSE values\n",
    "axes[2, 3].yaxis.set_major_formatter(FuncFormatter(one_decimal))\n",
    "axes[2, 3].set_xticks(np.arange(len(models)) + bar_width / 2)\n",
    "axes[2, 3].set_xticklabels(models)\n",
    "axes[2, 3].text(0.95, 0.95, bar_titles[3], transform=axes[2, 3].transAxes, verticalalignment='top', horizontalalignment='right')\n",
    "\n",
    "# Adjust layout and show the final figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Combined_Scatter_Bar_Plots_Fold2.png\", format='png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e937bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
